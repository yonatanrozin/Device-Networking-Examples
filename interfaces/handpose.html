<!DOCTYPE html>
<html>
    <head>
        <title>Mobile Handpose</title>
        <link rel="stylesheet" href="./styles.css" >
        <script src="https://unpkg.com/ml5@1.2.1/dist/ml5.min.js" type="text/javascript"></script>

        <script>

            async function startHandposeStream() {

                try {
                    const data = {};
                    const socket = new WebSocket("/messages");
                    function sendData() {socket.send(JSON.stringify(data))}
                    setInterval(sendData, 1000/30);

                    // See https://docs.ml5js.org/assets/handpose-keypoints-map.png for handpose keypoint numbers
                    const usedKeypoints = [0,4,8,12,16,20]; //place desired tracked hand keypoints in here
                    
                    //use {facingMode: "environment"} for rear-facing camera or {facingMode: "user"} for "selfie" cam
                    const stream = await navigator.mediaDevices.getUserMedia({video: {facingMode: "user"}});
                    
                    const handPose = await ml5.handPose({
                        maxHands: 1, //set to 2 to use both hands
                        flipped: true, //set to true on a front-facing "selfie" camera, otherwise false
                        runtime: "mediapipe",
                        modelType: "lite",
                    });                    
                    await handPose.ready;
                    
                    const video = document.createElement("video");
                    video.autoplay = true;
                    
                    video.srcObject = stream;
                    video.width = 640;
                    video.height = 480;
                                        
                    function handPoseDetect() {
                        handPose.detect(video, (hands) => {
                            data.hands = {};
                            hands.forEach((hand, i) => {
                                const keypoints = hand.keypoints;
                                data.hands[i] = {side: hand.handedness};
                                usedKeypoints.forEach(k => {
                                    const {x, y, name} = keypoints[k];
                                    data.hands[i][name] = [Math.round(x*100)/100, Math.round(y*100)/100];
                                });

                                // requires keypoints 4 and 8 in usedKeypoints
                                // data.hands[i].pinch = getPinch(data.hands[i]); 
                            });
                        });
                    }
                    setInterval(handPoseDetect, 1000/30);
                    
                    document.getElementById("ml-message").remove();
                } catch (e) {window.alert(e)}
            }

            window.addEventListener("DOMContentLoaded", () => {
                document.body.addEventListener("click", startHandposeStream, {once: true});
            });

            function getPinch(hand) {
                const [x1, y1] = hand.thumb_tip;
                const [x2, y2] = hand.index_finger_tip;
                return Math.sqrt(Math.pow(x1-x2, 2) + Math.pow(y1-y2, 2));
            }
        </script>
    </head>
    <body>
        <h1 id="ml-message">Tap screen to enable camera access + ML model (then wait a few secs)</h1>
    </body>
</html>
