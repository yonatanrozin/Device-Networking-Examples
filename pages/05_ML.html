<!DOCTYPE html>
<html>
    <head>
        <title>Mobile Handpose</title>
        <link rel="stylesheet" href="./styles.css" >
        <script src="./socket_script.js"></script>
        <script src="https://unpkg.com/ml5@1.2.1/dist/ml5.min.js" type="text/javascript"></script>

        <script>

            async function startHandposeStream() {

                try {

                    const usedKeypoints = [0,4,8,12,16,20]; //place desired tracked hand keypoints in here
                    // See https://docs.ml5js.org/assets/handpose-keypoints-map.png for handpose keypoint numbers
                    
                    //use {facingMode: "environment"} for rear-facing camera or {facingMode: "user"} for "selfie" cam
                    const stream = await navigator.mediaDevices.getUserMedia({video: {facingMode: "user"}});
                    
                    const handPose = await ml5.handPose({
                        maxHands: 1, //set to 2 to use both hands
                        flipped: true, //set to true on a front-facing "selfie" camera, otherwise false
                        runtime: "mediapipe",
                        modelType: "lite",
                    });
                    
                    await handPose.ready;
                    
                    const video = document.createElement("video");
                    video.autoplay = true;
                    
                    video.srcObject = stream;
                    video.width = 640;
                    video.height = 480;
                                        
                    function handPoseDetect() {
                        handPose.detect(video, (hands) => {
                            data.hands = {};
                            hands.forEach(({keypoints, handedness}, i) => {
                                data.hands[i] = {handedness};
                                usedKeypoints.forEach(k => {
                                    const {x, y, name} = keypoints[k];
                                    data.hands[i][name] = [Math.round(x*100)/100, Math.round(y*100)/100];
                                });
                            });
                        });
                    }
                    setInterval(handPoseDetect, 1000/60);
                    
                    document.getElementById("ml-message").remove();
                } catch (e) {window.alert(e)}
            }

            window.addEventListener("DOMContentLoaded", () => {
                document.body.addEventListener("click", () => startHandposeStream(), {once: true});
            });

        </script>
    </head>
    <body>
        <h1 id="ml-message">Tap screen to enable camera access + ML model (then wait a few secs)</h1>
    </body>
</html>
